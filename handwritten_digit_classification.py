# -*- coding: utf-8 -*-
"""Handwritten digit classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gw3HmI4otBHLb7TDz1A5k1arxaLB8eVq
"""

#checking VGA
# !nvidia-smi

# Commented out IPython magic to ensure Python compatibility.
#Importing libraries
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np

#intializin train, test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

len(x_train)

len(x_test)

x_train[0].shape

x_train[0]

plt.matshow(x_train[0])

y_train[0]

#To avoid exploding gradients
x_train = x_train/255
x_test = x_test/255

x_train[0]

#Reshaping the dataset to train
x_train_flattened = x_train.reshape(len(x_train), 28*28)
x_test_flattened = x_test.reshape(len(x_test), 28*28)

x_train_flattened.shape

x_train_flattened[0].shape

x_train_flattened[0]

#Model using no hidden layers
model1 = keras.Sequential([
                keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')          
])

model1.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model1.fit(x_train_flattened, y_train, epochs=5)

#Evaluate model
model1.evaluate(x_test_flattened, y_test)

y1_predict = model1.predict(x_test_flattened)
y1_predict[0]

plt.matshow(x_test[0])

np.argmax(y1_predict[0])

#Saving all prerdicted values to an array
y1_predicted_labels = [np.argmax(i) for i in y1_predict]

cm = tf.math.confusion_matrix(labels=y_test, predictions=y1_predicted_labels)
cm

import seaborn as sn
plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

#Using hidden layer
model2 = keras.Sequential([
                           keras.layers.Dense(100, input_shape=(784,), activation='relu'),
                           keras.layers.Dense(10, activation='sigmoid')
])

model2.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model2.fit(x_train_flattened, y_train, epochs=5)

model2.evaluate(x_test_flattened, y_test)

y2_predict = model2.predict(x_test_flattened)
y2_predicted_labels = [np.argmax(i) for i in y2_predict]
cm1 = tf.math.confusion_matrix(labels=y_test, predictions=y2_predicted_labels)
plt.figure(figsize = (10,7))
sn.heatmap(cm1, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

#Using keras flatten layer
model3 = keras.Sequential([
                           keras.layers.Flatten(input_shape=(28,28)),
                           keras.layers.Dense(100, activation='relu'),
                           keras.layers.Dense(10, activation='sigmoid')
])

model3.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model3.fit(x_train, y_train, epochs=10)

model3.evaluate(x_test, y_test)

y3_predict = model3.predict(x_test)
y3_predicted_labels = [np.argmax(i) for i in y3_predict]
cm2 = tf.math.confusion_matrix(labels=y_test, predictions=y3_predicted_labels)
plt.figure(figsize = (10,7))
sn.heatmap(cm2, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')